# -*- coding: utf-8 -*-
"""Nuri_Hidayatuloh_Submission1_Machine_Learning_Intermediate_Lv_Lintasarta_Cloudeka_Digischool_&_Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Or6g5Jw51N6T7bEbKs_pUwPxAN-pkAdB

**IMPORT LIBRARY**

##### Memastikan Versi Tensorflow
"""

import tensorflow as tf
print(tf.__version__)

"""##### Download Dataset"""

# !wget

"""##### Load Dataset"""

import pandas as pd

df = pd.read_csv('cuaca.csv', low_memory=False)
df

"""##### Informasi Dataset"""

df.info()

"""##### Simplified Dataset"""

df = df[['Date', 'MeanTemp']]
df

df = df.iloc[:11000]

df.info()

df

df = df[df['MeanTemp'] >= 20.000000]

df

"""##### Menampilkan dalam Bentuk Grafik"""

import matplotlib.pyplot as plt

dates = df['Date'].values
temp  = df['MeanTemp'].values

plt.figure(figsize=(15,5))
plt.plot(df['Date'].values, df['MeanTemp'].values)
plt.title('CUACA', fontsize=18)

"""##### Input Missing Value"""

import datetime
from datetime import date

df = df.copy()

#  format date dalam bentuk Year, month dan day
df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')

# set date menjadi index
dataset= df.set_index('Date')

# cek data shape
dataset.shape

dataset.head()

"""#### Membuat Series True or False"""

nul_data = pd.isnull(dataset['MeanTemp'])

# print only the data, mean_temp = NaN
dataset[nul_data].head()

plt.rcParams['figure.figsize']=(15,7)

# untuk mengisi data yang hilang menggunakan mean dari data
dataset = dataset.assign(FillMeanTemp=dataset.MeanTemp.fillna(dataset.MeanTemp.mean()))

plt.plot(dataset, color='blue')

plt.title('Mean Temp Imputation')

plt.show()

dataset.head()

dataset.shape

dataset.reset_index(drop=False, inplace=True) #mengembalikan index date ke data semula

dataset.info()

dataset.isnull().sum()

"""##### Normalisasi"""

from sklearn import preprocessing
import numpy as np


scaler = preprocessing.MinMaxScaler()
tmp_scaler = scaler.fit_transform(dataset['FillMeanTemp'].values.reshape(-1,1))
tmp_scaler

tmp_fix = tmp_scaler.reshape(-1)

"""##### Splitting Data"""

from sklearn.model_selection import train_test_split

#melatih data latih dan data uji
dt_train, dt_test, tmp_train, tmp_test = train_test_split(dataset['Date'].values, tmp_fix, test_size=0.2, shuffle=False)
print(dt_train.shape, tmp_train.shape)
print(dt_test.shape, tmp_test.shape)

"""#### Mengubah Data agar bisa dibaca oleh Model"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

X_set = windowed_dataset(tmp_train, window_size=60,
                             batch_size=100, shuffle_buffer=1000)
Y_set = windowed_dataset(tmp_test, window_size=60,
                           batch_size=100, shuffle_buffer=1000)

"""## MODELLING"""

from keras.models import Sequential
from keras.layers import Bidirectional, Dense, LSTM, Dropout

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60)),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dropout(0.3),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

"""#### Optimizer"""

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=['mae'])

"""#### Batas Nilai MAE"""

max_mae = (tmp_fix.max() - tmp_fix.min()) * 10/100
print(f'Batas Nilai MAE harus dibawah -> {max_mae}')

"""#### Callback"""

class stop(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if (logs.get('mae') < 0.1):
      self.model.stop_training = True
      print('\nBatas Nilai MAE < 10% sudah terlampaui!')
Callback = stop()

"""#### Accuracy"""

history = model.fit(X_set,
                    validation_data = Y_set, # menampilkan akurasi pengujian data validasi
                    epochs=500, batch_size=60,
                    callbacks = [Callback])

"""#### Visualisasi Grafik"""

import numpy as np

maee = history.history['mae']
val_mae = history.history['val_mae']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(maee))

plt.figure(figsize=(20, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, maee, label='Training MAE')
plt.plot(epochs_range, val_mae, label='Validation MAE')
plt.legend(loc='upper right')
plt.grid(True)
plt.title('Training and Validation MAE')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.grid(True)
plt.title('Training and Validation Loss')